{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similaridade de Textos: LSH\n",
    "\n",
    "## Locality-Sensitive Hashing (LSH) Algorithms\n",
    "\n",
    "LSH for Euclidean distance metrics. The input is a dense or sparse vectors, each of which represents a point in the Euclidean distance space. The output will be vectors of configurable dimension. Hash values in the same dimension are calculated by the same hash function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import time, os, string\n",
    "\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import regexp_replace, trim, col, lower, when, size, lit, avg\n",
    "\n",
    "def removePunctuation(column):\n",
    "    return trim(lower(regexp_replace(column,'[^\\sa-zA-Z0-9]',''))).alias('text')\n",
    "\n",
    "class RemoveEmptyLines(Transformer):\n",
    "    def __init__(self, column: StringType() ):\n",
    "        super(RemoveEmptyLines, self).__init__()\n",
    "        self.column = column\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        return df.withColumn(self.column, when(size(col(self.column)) == 0, lit(None)).otherwise(col(self.column))).na.drop()\n",
    "        #return df\n",
    "\n",
    "cwd = os.getcwd()\n",
    "book_folder = \"/data/\"\n",
    "dubliners = 'file://'+cwd+book_folder+\"Dubliners_James_Joyce.txt.gz\"\n",
    "ulysses= 'file://'+cwd+book_folder+\"Ulysses_James_Joyce.txt.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local Spark session\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"SparkSimilarityLSH\")\\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+\n",
      "|value                                                              |\n",
      "+-------------------------------------------------------------------+\n",
      "|                                                                   |\n",
      "|The Project Gutenberg EBook of Ulysses, by James Joyce             |\n",
      "|                                                                   |\n",
      "|This eBook is for the use of anyone anywhere at no cost and with   |\n",
      "|almost no restrictions whatsoever. You may copy it, give it away or|\n",
      "|re-use it under the terms of the Project Gutenberg License included|\n",
      "|with this eBook or online at www.gutenberg.org                     |\n",
      "|                                                                   |\n",
      "|                                                                   |\n",
      "|Title: Ulysses                                                     |\n",
      "+-------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|value                                                              |\n",
      "+-------------------------------------------------------------------+\n",
      "|The Project Gutenberg EBook of Ulysses, by James Joyce             |\n",
      "|This eBook is for the use of anyone anywhere at no cost and with   |\n",
      "|almost no restrictions whatsoever. You may copy it, give it away or|\n",
      "|re-use it under the terms of the Project Gutenberg License included|\n",
      "|with this eBook or online at www.gutenberg.org                     |\n",
      "|Title: Ulysses                                                     |\n",
      "|Author: James Joyce                                                |\n",
      "|Release Date: August 1, 2008 [EBook #4300]                         |\n",
      "|Last Updated: October 30, 2018                                     |\n",
      "|Language: English                                                  |\n",
      "+-------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------------------------------+\n",
      "|text                                                              |\n",
      "+------------------------------------------------------------------+\n",
      "|the project gutenberg ebook of ulysses by james joyce             |\n",
      "|this ebook is for the use of anyone anywhere at no cost and with  |\n",
      "|almost no restrictions whatsoever you may copy it give it away or |\n",
      "|reuse it under the terms of the project gutenberg license included|\n",
      "|with this ebook or online at wwwgutenbergorg                      |\n",
      "|title ulysses                                                     |\n",
      "|author james joyce                                                |\n",
      "|release date august 1 2008 ebook 4300                             |\n",
      "|last updated october 30 2018                                      |\n",
      "|language english                                                  |\n",
      "+------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read de book file: Ulysses \n",
    "text_1 = spark.read.text(ulysses)\n",
    "text_1.show(10, truncate = False)\n",
    "text_1 = text_1.filter(\"value != ''\")\n",
    "text_1.show(10, truncate = False)\n",
    "text_1 = text_1.select(removePunctuation(col('value')))\n",
    "text_1 = text_1.withColumnRenamed('value', 'text')\n",
    "text_1.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+\n",
      "|text                                                              |\n",
      "+------------------------------------------------------------------+\n",
      "|the project gutenberg ebook of dubliners by james joyce           |\n",
      "|this ebook is for the use of anyone anywhere at no cost and with  |\n",
      "|almost no restrictions whatsoever you may copy it give it away or |\n",
      "|reuse it under the terms of the project gutenberg license included|\n",
      "|with this ebook or online at wwwgutenbergorg                      |\n",
      "|title dubliners                                                   |\n",
      "|author james joyce                                                |\n",
      "|release date september 2001 ebook 2814                            |\n",
      "|last updated january 20 2019                                      |\n",
      "|language english                                                  |\n",
      "+------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read de book file:  Dubliner\n",
    "text_2 = spark.read.text(dubliners)\n",
    "text_2 = text_2.filter(\"value != ''\")\n",
    "text_2 = text_2.select(removePunctuation(col('value')))\n",
    "text_2 = text_2.withColumnRenamed('value', 'text')\n",
    "text_2.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity\n",
    "\n",
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|              tokens|\n",
      "+--------------------+--------------------+\n",
      "|the project guten...|[the, project, gu...|\n",
      "|this ebook is for...|[this, ebook, for...|\n",
      "|almost no restric...|[almost, restrict...|\n",
      "|reuse it under th...|[reuse, under, th...|\n",
      "|with this ebook o...|[with, this, eboo...|\n",
      "|       title ulysses|    [title, ulysses]|\n",
      "|  author james joyce|[author, james, j...|\n",
      "|release date augu...|[release, date, a...|\n",
      "|last updated octo...|[last, updated, o...|\n",
      "|    language english| [language, english]|\n",
      "|character set enc...|[character, set, ...|\n",
      "|start of this pro...|[start, this, pro...|\n",
      "|produced by col c...|[produced, col, c...|\n",
      "|               cover|             [cover]|\n",
      "|             ulysses|           [ulysses]|\n",
      "|      by james joyce|      [james, joyce]|\n",
      "|            contents|          [contents]|\n",
      "|                   i|                  []|\n",
      "|                   1|                  []|\n",
      "|                   2|                  []|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer(pattern='\\s+', inputCol=\"text\", outputCol=\"tokens\", minTokenLength=3, toLowercase=True)\n",
    "#tokenizer = RegexTokenizer(pattern=\"\", inputCol=\"text\", outputCol=\"tokens\", minTokenLength=1, toLowercase=True)\n",
    "#tokenizer = RegexTokenizer(pattern=\"\", inputCol=\"text\", outputCol=\"tokens\", minTokenLength=1)\n",
    "\n",
    "tokenData = tokenizer.transform(text_1)\n",
    "tokenData.show() #(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shingling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|              tokens|              ngrams|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|the project guten...|[the, project, gu...|[the project gute...|\n",
      "|this ebook is for...|[this, ebook, for...|[this ebook for, ...|\n",
      "|almost no restric...|[almost, restrict...|[almost restricti...|\n",
      "|reuse it under th...|[reuse, under, th...|[reuse under the,...|\n",
      "|with this ebook o...|[with, this, eboo...|[with this ebook,...|\n",
      "|  author james joyce|[author, james, j...|[author james joyce]|\n",
      "|release date augu...|[release, date, a...|[release date aug...|\n",
      "|last updated octo...|[last, updated, o...|[last updated oct...|\n",
      "|character set enc...|[character, set, ...|[character set en...|\n",
      "|start of this pro...|[start, this, pro...|[start this proje...|\n",
      "|produced by col c...|[produced, col, c...|[produced col cho...|\n",
      "|stately plump buc...|[stately, plump, ...|[stately plump bu...|\n",
      "|lather on which a...|[lather, which, m...|[lather which mir...|\n",
      "|dressinggown ungi...|[dressinggown, un...|[dressinggown ung...|\n",
      "|morning air he he...|[morning, air, he...|[morning air held...|\n",
      "|introibo ad altar...|[introibo, altare...|[introibo altare ...|\n",
      "|halted he peered ...|[halted, peered, ...|[halted peered do...|\n",
      "|come up kinch com...|[come, kinch, com...|[come kinch come,...|\n",
      "|solemnly he came ...|[solemnly, came, ...|[solemnly came fo...|\n",
      "|and blessed grave...|[and, blessed, gr...|[and blessed grav...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = NGram(n=3, inputCol=\"tokens\", outputCol=\"ngrams\")\n",
    "ngramData = ngram.transform(tokenData)\n",
    "\n",
    "rememptylines = RemoveEmptyLines(column = \"ngrams\")\n",
    "ngramData = rememptylines.transform(ngramData)\n",
    "\n",
    "#ngramData = ngramData.withColumn(\"ngrams\", when(size(col(\"ngrams\")) == 0, lit(None)).otherwise(col(\"ngrams\"))).na.drop()\n",
    "ngramData.show() #(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|              tokens|              ngrams|             vectors|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|the project guten...|[the, project, gu...|[the project gute...|(262144,[11558,11...|\n",
      "|this ebook is for...|[this, ebook, for...|[this ebook for, ...|(262144,[18308,32...|\n",
      "|almost no restric...|[almost, restrict...|[almost restricti...|(262144,[10891,10...|\n",
      "|reuse it under th...|[reuse, under, th...|[reuse under the,...|(262144,[52778,86...|\n",
      "|with this ebook o...|[with, this, eboo...|[with this ebook,...|(262144,[13156,17...|\n",
      "|  author james joyce|[author, james, j...|[author james joyce]|(262144,[19040],[...|\n",
      "|release date augu...|[release, date, a...|[release date aug...|(262144,[111497,1...|\n",
      "|last updated octo...|[last, updated, o...|[last updated oct...|(262144,[25383,13...|\n",
      "|character set enc...|[character, set, ...|[character set en...|(262144,[180245,2...|\n",
      "|start of this pro...|[start, this, pro...|[start this proje...|(262144,[87818,11...|\n",
      "|produced by col c...|[produced, col, c...|[produced col cho...|(262144,[32547,51...|\n",
      "|stately plump buc...|[stately, plump, ...|[stately plump bu...|(262144,[11455,17...|\n",
      "|lather on which a...|[lather, which, m...|[lather which mir...|(262144,[11671,55...|\n",
      "|dressinggown ungi...|[dressinggown, un...|[dressinggown ung...|(262144,[105738,1...|\n",
      "|morning air he he...|[morning, air, he...|[morning air held...|(262144,[40490,62...|\n",
      "|introibo ad altar...|[introibo, altare...|[introibo altare ...|(262144,[68797],[...|\n",
      "|halted he peered ...|[halted, peered, ...|[halted peered do...|(262144,[20340,54...|\n",
      "|come up kinch com...|[come, kinch, com...|[come kinch come,...|(262144,[147548,1...|\n",
      "|solemnly he came ...|[solemnly, came, ...|[solemnly came fo...|(262144,[31853,58...|\n",
      "|and blessed grave...|[and, blessed, gr...|[and blessed grav...|(262144,[64415,10...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hash_tf = HashingTF(inputCol=\"ngrams\", outputCol=\"vectors\")\n",
    "\n",
    "hashtfData = hash_tf.transform(ngramData)\n",
    "hashtfData.show() #truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|              tokens|              ngrams|             vectors|                 lsh|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|the project guten...|[the, project, gu...|[the project gute...|(262144,[11558,11...|[[1.41920939E8], ...|\n",
      "|this ebook is for...|[this, ebook, for...|[this ebook for, ...|(262144,[18308,32...|[[3.06401254E8], ...|\n",
      "|almost no restric...|[almost, restrict...|[almost restricti...|(262144,[10891,10...|[[5.5546337E7], [...|\n",
      "|reuse it under th...|[reuse, under, th...|[reuse under the,...|(262144,[52778,86...|[[1.41920939E8], ...|\n",
      "|with this ebook o...|[with, this, eboo...|[with this ebook,...|(262144,[13156,17...|[[2.99715787E8], ...|\n",
      "|  author james joyce|[author, james, j...|[author james joyce]|(262144,[19040],[...|[[1.078648149E9],...|\n",
      "|release date augu...|[release, date, a...|[release date aug...|(262144,[111497,1...|[[2.69617508E8], ...|\n",
      "|last updated octo...|[last, updated, o...|[last updated oct...|(262144,[25383,13...|[[8.60499945E8], ...|\n",
      "|character set enc...|[character, set, ...|[character set en...|(262144,[180245,2...|[[7.45750494E8], ...|\n",
      "|start of this pro...|[start, this, pro...|[start this proje...|(262144,[87818,11...|[[6.00506029E8], ...|\n",
      "|produced by col c...|[produced, col, c...|[produced col cho...|(262144,[32547,51...|[[1.75384835E8], ...|\n",
      "|stately plump buc...|[stately, plump, ...|[stately plump bu...|(262144,[11455,17...|[[1.24106025E8], ...|\n",
      "|lather on which a...|[lather, which, m...|[lather which mir...|(262144,[11671,55...|[[4.89762659E8], ...|\n",
      "|dressinggown ungi...|[dressinggown, un...|[dressinggown ung...|(262144,[105738,1...|[[3.84179288E8], ...|\n",
      "|morning air he he...|[morning, air, he...|[morning air held...|(262144,[40490,62...|[[6.51428183E8], ...|\n",
      "|introibo ad altar...|[introibo, altare...|[introibo altare ...|(262144,[68797],[...|[[1.428709963E9],...|\n",
      "|halted he peered ...|[halted, peered, ...|[halted peered do...|(262144,[20340,54...|[[1.79096817E8], ...|\n",
      "|come up kinch com...|[come, kinch, com...|[come kinch come,...|(262144,[147548,1...|[[8.95933707E8], ...|\n",
      "|solemnly he came ...|[solemnly, came, ...|[solemnly came fo...|(262144,[31853,58...|[[3.90449334E8], ...|\n",
      "|and blessed grave...|[and, blessed, gr...|[and blessed grav...|(262144,[64415,10...|[[4.17979258E8], ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#minhash = MinHashLSH(inputCol=\"vectors\", outputCol=\"lsh\", numHashTables=5).fit(hashtfData)\n",
    "minhash = MinHashLSH(inputCol=\"vectors\", outputCol=\"lsh\", numHashTables=3).fit(hashtfData)\n",
    "\n",
    "minhashData = minhash.transform(hashtfData)\n",
    "minhashData.show() #truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|              tokens|              ngrams|             vectors|                 lsh|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|the project guten...|[the, project, gu...|[the project gute...|(262144,[11558,11...|[[1.41920939E8], ...|\n",
      "|this ebook is for...|[this, ebook, for...|[this ebook for, ...|(262144,[18308,32...|[[3.06401254E8], ...|\n",
      "|almost no restric...|[almost, restrict...|[almost restricti...|(262144,[10891,10...|[[5.5546337E7], [...|\n",
      "|reuse it under th...|[reuse, under, th...|[reuse under the,...|(262144,[52778,86...|[[1.41920939E8], ...|\n",
      "|with this ebook o...|[with, this, eboo...|[with this ebook,...|(262144,[13156,17...|[[2.99715787E8], ...|\n",
      "|  author james joyce|[author, james, j...|[author james joyce]|(262144,[19040],[...|[[1.078648149E9],...|\n",
      "|release date augu...|[release, date, a...|[release date aug...|(262144,[111497,1...|[[2.69617508E8], ...|\n",
      "|last updated octo...|[last, updated, o...|[last updated oct...|(262144,[25383,13...|[[8.60499945E8], ...|\n",
      "|character set enc...|[character, set, ...|[character set en...|(262144,[180245,2...|[[7.45750494E8], ...|\n",
      "|start of this pro...|[start, this, pro...|[start this proje...|(262144,[87818,11...|[[6.00506029E8], ...|\n",
      "|produced by col c...|[produced, col, c...|[produced col cho...|(262144,[32547,51...|[[1.75384835E8], ...|\n",
      "|stately plump buc...|[stately, plump, ...|[stately plump bu...|(262144,[11455,17...|[[1.24106025E8], ...|\n",
      "|lather on which a...|[lather, which, m...|[lather which mir...|(262144,[11671,55...|[[4.89762659E8], ...|\n",
      "|dressinggown ungi...|[dressinggown, un...|[dressinggown ung...|(262144,[105738,1...|[[3.84179288E8], ...|\n",
      "|morning air he he...|[morning, air, he...|[morning air held...|(262144,[40490,62...|[[6.51428183E8], ...|\n",
      "|introibo ad altar...|[introibo, altare...|[introibo altare ...|(262144,[68797],[...|[[1.428709963E9],...|\n",
      "|halted he peered ...|[halted, peered, ...|[halted peered do...|(262144,[20340,54...|[[1.79096817E8], ...|\n",
      "|come up kinch com...|[come, kinch, com...|[come kinch come,...|(262144,[147548,1...|[[8.95933707E8], ...|\n",
      "|solemnly he came ...|[solemnly, came, ...|[solemnly came fo...|(262144,[31853,58...|[[3.90449334E8], ...|\n",
      "|and blessed grave...|[and, blessed, gr...|[and blessed grav...|(262144,[64415,10...|[[4.17979258E8], ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "            tokenizer,\n",
    "            ngram,\n",
    "            rememptylines,\n",
    "            hash_tf,\n",
    "            minhash\n",
    "        ])\n",
    "\n",
    "model= pipeline.fit(text_1)\n",
    "\n",
    "text_A = model.transform(text_1)\n",
    "text_B = model.transform(text_2)\n",
    "\n",
    "text_A.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|              tokens|              ngrams|             vectors|                 lsh|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|the project guten...|[the, project, gu...|[the project gute...|(262144,[144429,1...|[[1.41920939E8], ...|\n",
      "|this ebook is for...|[this, ebook, for...|[this ebook for, ...|(262144,[18308,32...|[[3.06401254E8], ...|\n",
      "|almost no restric...|[almost, restrict...|[almost restricti...|(262144,[10891,10...|[[5.5546337E7], [...|\n",
      "|reuse it under th...|[reuse, under, th...|[reuse under the,...|(262144,[52778,86...|[[1.41920939E8], ...|\n",
      "|with this ebook o...|[with, this, eboo...|[with this ebook,...|(262144,[13156,17...|[[2.99715787E8], ...|\n",
      "|  author james joyce|[author, james, j...|[author james joyce]|(262144,[19040],[...|[[1.078648149E9],...|\n",
      "|release date sept...|[release, date, s...|[release date sep...|(262144,[3022,794...|[[2.45294507E8], ...|\n",
      "|last updated janu...|[last, updated, j...|[last updated jan...|(262144,[215486,2...|[[7.59719917E8], ...|\n",
      "|character set enc...|[character, set, ...|[character set en...|(262144,[180245,2...|[[7.45750494E8], ...|\n",
      "|start of this pro...|[start, this, pro...|[start this proje...|(262144,[87818,14...|[[6.00506029E8], ...|\n",
      "|produced by david...|[produced, david,...|[produced david r...|(262144,[77076,84...|[[1.215020633E9],...|\n",
      "|      after the race|  [after, the, race]|    [after the race]|(262144,[99238],[...|[[2.35880095E8], ...|\n",
      "|  the boarding house|[the, boarding, h...|[the boarding house]|(262144,[73077],[...|[[4.44924776E8], ...|\n",
      "|ivy day in the co...|[ivy, day, the, c...|[ivy day the, day...|(262144,[20147,78...|[[6.82770018E8], ...|\n",
      "|there was no hope...|[there, was, hope...|[there was hope, ...|(262144,[53034,77...|[[9.6175574E7], [...|\n",
      "|after night i had...|[after, night, ha...|[after night had,...|(262144,[5201,338...|[[1.08271268E8], ...|\n",
      "|the lighted squar...|[the, lighted, sq...|[the lighted squa...|(262144,[17461,30...|[[3.59775044E8], ...|\n",
      "|lighted in the sa...|[lighted, the, sa...|[lighted the same...|(262144,[60179,60...|[[6.2544589E7], [...|\n",
      "|i would see the r...|[would, see, the,...|[would see the, s...|(262144,[53144,91...|[[6.3681717E7], [...|\n",
      "|that two candles ...|[that, two, candl...|[that two candles...|(262144,[30056,75...|[[2.40178379E8], ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_B.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locality-Sensitive Hashing (LSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|            datasetA|            datasetB|   JaccardDistance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|[before cheese i ...|[read the paragra...|0.8823529411764706|\n",
      "|[performances and...|[performances and...|               0.0|\n",
      "|[united states an...|[united states an...|               0.0|\n",
      "|[where did you ge...|[who did you get ...|0.8571428571428572|\n",
      "|[house of stephen...|[why asked miss i...|0.8571428571428572|\n",
      "|[or any other wor...|[or any other wor...|               0.0|\n",
      "|[1e1 the followin...|[1e1 the followin...|               0.0|\n",
      "|[access to or dis...|[access to or dis...|               0.0|\n",
      "|[or entity provid...|[or entity provid...|               0.0|\n",
      "|[production promo...|[distribution of ...|               0.8|\n",
      "|[for additional c...|[for additional c...|               0.0|\n",
      "|[including how to...|[generations to l...|               0.8|\n",
      "|[father conmee tu...|[she turned away ...|0.8823529411764706|\n",
      "|[to the owner of ...|[to the owner of ...|               0.0|\n",
      "|[state visit wwwg...|[state visit wwwg...|               0.0|\n",
      "|[charley youre my...|[that was why, [t...|0.8571428571428572|\n",
      "|[saint stephens h...|[the coffin said ...|0.8888888888888888|\n",
      "|[bloom on this da...|[we have one chil...|0.8888888888888888|\n",
      "|[something like t...|[something like t...|0.8571428571428572|\n",
      "|[with which atten...|[a garret lit by ...|             0.875|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Similarity Ulysses x Dubliners =  15.204098496116345  %\n"
     ]
    }
   ],
   "source": [
    "rows_text_A = text_A.count()\n",
    "rows_text_B = text_B.count()\n",
    "\n",
    "# Show similarity with Jaccard Distance below 0.9\n",
    "result_A_B = model.stages[-1].approxSimilarityJoin(text_A, text_B, 0.9, distCol=\"JaccardDistance\")\n",
    "result_A_B.show()\n",
    "\n",
    "rows_result_A_B = result_A_B.count()\n",
    "simil_index_AB = rows_result_A_B / rows_text_B * 100\n",
    "print(\"Similarity Ulysses x Dubliners = \",simil_index_AB, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+\n",
      "|            datasetA|            datasetB|JaccardDistance|\n",
      "+--------------------+--------------------+---------------+\n",
      "|[well i mean it h...|[well i mean it h...|            0.0|\n",
      "|[five fathoms out...|[five fathoms out...|            0.0|\n",
      "|[the pillars prie...|[the pillars prie...|            0.0|\n",
      "|[me from her door...|[me from her door...|            0.0|\n",
      "|[his hand accepte...|[his hand accepte...|            0.0|\n",
      "|[felt its way und...|[felt its way und...|            0.0|\n",
      "|[if im not there ...|[if im not there ...|            0.0|\n",
      "|[the chemist turn...|[the chemist turn...|            0.0|\n",
      "|[wheeling by farr...|[wheeling by farr...|            0.0|\n",
      "|[and madame twent...|[and madame twent...|            0.0|\n",
      "|[pawning the furn...|[pawning the furn...|            0.0|\n",
      "|[with a fluent cr...|[with a fluent cr...|            0.0|\n",
      "|[the priest close...|[the priest close...|            0.0|\n",
      "|[the thing else t...|[the thing else t...|            0.0|\n",
      "|[poor dead smell ...|[poor dead smell ...|            0.0|\n",
      "|[with stones that...|[with stones that...|            0.0|\n",
      "|[tramway companys...|[tramway companys...|            0.0|\n",
      "|[stately figure e...|[stately figure e...|            0.0|\n",
      "|[hello jack thats...|[hello jack thats...|            0.0|\n",
      "|[whats that myles...|[whats that myles...|            0.0|\n",
      "+--------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Similarity Ulysses x Ulysses =  100.12509382036528  %\n"
     ]
    }
   ],
   "source": [
    "# Show similarity with Jaccard Distance below 0.5\n",
    "result_A_A = model.stages[-1].approxSimilarityJoin(text_A, text_A, 0.5, distCol=\"JaccardDistance\")\n",
    "result_A_A .show()\n",
    "\n",
    "simil_index_AA = result_A_A.count() / rows_text_A * 100\n",
    "print(\"Similarity Ulysses x Ulysses = \",simil_index_AA, \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Execution time: 73.51522588729858 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "# Stop Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
