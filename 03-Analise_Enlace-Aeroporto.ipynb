{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo 03: Análise de Enlace\n",
    "## Identificação de Aeroportos com mais conectividade\n",
    "\n",
    "Muitos problemas em ciência de dados podem ser modelados com um grafo. Um exemplo é a análise da rede aérea em uma região, onde os vertices são os aeroportos e as areastas são as linhas aéreas. Usando algoritmos de análise de enlace podemos extrair informações como aeroportos mais movimentados e menor caminho entre duas localidades.\n",
    "\n",
    "Porém essa análise não é tão trivial. A maneira mais simples de determinar o aeroporto mais movimentado é contar o número de voos realizados de e para esta cidade. No entanto, como a maioria das companhias aéreas utiliza um sistema de *hub-and-spoke*, a simples contagem dos voos de entrada e saída não transmite a importância do aeroporto para o tráfego aéreo geral. Isso ocorre porque determinados aeroportos centrais podem ser pontos de passagem para os vôos em outros aeroportos e, como resultado, esses aeroportos centrais podem ser considerados mais importantes, mesmo que tenham contagens total de voos seja igual ou até menores.\n",
    "\n",
    "O algoritmo Pagerank foi originalmente criado para medir a importância relativa das páginas da web, avaliando os links de ligação da página. Qualquer página da web é considerada mais importante se outras páginas importantes tiverem links para essa página. Podemos aplicar esse mesmo conceito de importância aos aeroportos. Se você substituir “página da web” por “aeroporto” e substituir “link da web” por “voo da companhia aérea”, poderá ver que o PageRank pode ser usado para avaliar a importância de um aeroporto. O PageRank acaba sendo uma boa maneira de medir a importância do aeroporto, dado o uso do molelo *hub-and-spoke* usado pelas companhias hub e spoke das companhias aéreas. Um aeroporto importante acabaria sendo um aeroporto que por si só é um *hub* no qual outros aeroportos possuem muitos vôos ou um “hub de hubs”.\n",
    "\n",
    "Para este exemplo vamos usar uma base de dados de aeroportos e voos nos Estados Unidos e Canada. Então, para identificar os aeroportos mais importantes da região, considerando como um determinado aeroporto influencia os vôos para outros aeroportos, podemos usar o algoritmo Pagerank. Este exemplo mostra os aeroportos com mais voos e os aeroportos mais conectados calculados pelo Pagerank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import Graphframes lib\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "data_path='./data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://repos.spark-packages.org added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /user/home/marcial/.ivy2/cache\n",
      "The jars for the packages stored in: /user/home/marcial/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-71a81e71-aea3-49a3-b946-298659b837fb;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound graphframes#graphframes;0.8.3-spark3.4-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 360ms :: artifacts dl 41ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.3-spark3.4-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-71a81e71-aea3-49a3-b946-298659b837fb\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/16ms)\n",
      "24/04/21 11:13:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Cria Spark Session\n",
    "sc = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"LinkAnalisysAirlines\") \\\n",
    "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.3-spark3.4-s_2.12\") \\\n",
    "    .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airports\n",
    "\n",
    "| Field | Description |\n",
    "| --------- | :-------------: |\n",
    "| node_id | Unique identifier for the airport. |\n",
    "| name | Name of airport or city and state.|\n",
    "| metro_pop | City/region population.|\n",
    "| latitude | Airport latitude |\n",
    "| longitude | Airport longitude |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airports number:  456\n",
      "+-------+--------------------+---------+---------+-----------+\n",
      "|node_id|                name|metro_pop| latitude|  longitude|\n",
      "+-------+--------------------+---------+---------+-----------+\n",
      "|      0|      Abbotsford, BC| 133497.0|49.051575|-122.328849|\n",
      "|      1|        Aberdeen, SD|  40878.0| 45.45909| -98.487324|\n",
      "|      2|         Abilene, TX| 166416.0|32.449175| -99.741424|\n",
      "|      3|    Akron/Canton, OH| 701456.0| 40.79781| -81.371567|\n",
      "|      4|         Alamosa, CO|   9433.0| 37.46818|-105.873599|\n",
      "|      5|          Albany, GA| 157688.0| 31.58076| -84.155989|\n",
      "|      6|          Albany, NY| 871478.0|42.651455| -73.755274|\n",
      "|      7|     Albuquerque, NM| 898642.0| 35.08418|-106.648639|\n",
      "|      8|      Alexandria, LA| 154505.0|31.312685| -92.445649|\n",
      "|      9|Allentown/Bethleh...| 824916.0|40.651428| -75.434219|\n",
      "|     10|        Alliance, NE|   8499.0| 42.09712|-102.871454|\n",
      "|     11|          Alpena, MI|  29386.0|45.061565| -83.445154|\n",
      "|     12|         Altoona, PA| 127099.0| 40.50719| -78.398904|\n",
      "|     13|        Amarillo, TX| 253823.0|35.207255|-101.833894|\n",
      "|     14|       Anchorage, AK| 387516.0| 61.21756|-149.857749|\n",
      "|     15|        Appleton, WI| 227403.0| 44.26178| -88.416564|\n",
      "|     16|       Asheville, NC| 429017.0| 35.59846| -82.553144|\n",
      "|     17|           Aspen, CO|   6680.0| 39.19003|-106.818184|\n",
      "|     18|          Athens, GA| 193317.0|33.958132| -83.373255|\n",
      "|     19|         Atlanta, GA|5359000.0|33.748315| -84.391109|\n",
      "+-------+--------------------+---------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Le arquivo de dados Airport para Dataframe Spark\n",
    "\n",
    "airport = sc.read.format(\"csv\").options(sep=',',header='true',inferschema='true').\\\n",
    "         load(data_path+\"reachability-meta.csv.gz\")\n",
    "\n",
    "#Exibe campos da tabela e os tipos de dados\n",
    "#airport.dtypes\n",
    "print(\"Airports number: \",airport.count())\n",
    "airport.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flights\n",
    "\n",
    "| Field | Description |\n",
    "| --------- | :-------------: |\n",
    "| FromNodeId | Origin airport (node_id).|\n",
    "| ToNodeId | Destination airport (node_id).|\n",
    "| Weight | Distance |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fligths number:  71959\n",
      "+----------+--------+------+\n",
      "|FromNodeId|ToNodeId|Weight|\n",
      "+----------+--------+------+\n",
      "|        27|       0|  -757|\n",
      "|        57|       0|   -84|\n",
      "|        70|       0| -1290|\n",
      "|        74|       0|  -465|\n",
      "|        86|       0|  -700|\n",
      "|        94|       0|  -526|\n",
      "|       100|       0|  -448|\n",
      "|       113|       0|   -90|\n",
      "|       138|       0|  -256|\n",
      "|       154|       0|  -270|\n",
      "|       166|       0|  -515|\n",
      "|       178|       0|  -400|\n",
      "|       230|       0|  -486|\n",
      "|       235|       0|  -170|\n",
      "|       242|       0|  -469|\n",
      "|       246|       0|  -325|\n",
      "|       262|       0|  -200|\n",
      "|       269|       0|  -525|\n",
      "|       275|       0|  -585|\n",
      "|       280|       0|  -405|\n",
      "+----------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Le arquivo de dados Linhas Aereas para Dataframe Spark\n",
    "\n",
    "routes = sc.read.format(\"csv\").options(sep=' ',header='true',inferschema='true').\\\n",
    "          load(data_path+\"reachability.txt.gz\")\n",
    "\n",
    "#routes.dtypes\n",
    "print(\"Fligths number: \",routes.count())\n",
    "routes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|            name|\n",
      "+---+----------------+\n",
      "|  0|  Abbotsford, BC|\n",
      "|  1|    Aberdeen, SD|\n",
      "|  2|     Abilene, TX|\n",
      "|  3|Akron/Canton, OH|\n",
      "|  4|     Alamosa, CO|\n",
      "+---+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extrair campos relevantes para definir os vertices do grafo\n",
    "vertice = airport.select(\"node_id\",\"name\")\n",
    "\n",
    "# Graphframe exige que coluna com identificação do vertice possua nome 'id'\n",
    "# Troca nome \"node_id\" por \"id\"\n",
    "vertice = vertice.withColumnRenamed(\"node_id\", \"id\").cache()\n",
    "\n",
    "#caso precise converter algum campo\n",
    "#vertice = vertice.withColumn(\"id\", vertice[\"id\"].cast(\"string\"))\n",
    "\n",
    "airport_name = airport.select(\"node_id\", \"name\").withColumnRenamed(\"node_id\", \"id\")\n",
    "\n",
    "#vertice.dtypes\n",
    "vertice.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+\n",
      "|src|dst|Weight|\n",
      "+---+---+------+\n",
      "| 27|  0|  -757|\n",
      "| 57|  0|   -84|\n",
      "| 70|  0| -1290|\n",
      "| 74|  0|  -465|\n",
      "| 86|  0|  -700|\n",
      "+---+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extrair campos relevantes para definir os arestas do grafo\n",
    "edge = routes.select(\"FromNodeId\",\"ToNodeId\",\"Weight\")\n",
    "\n",
    "# Graphframe exige que colunas com identificação das arestas possua nome 'src' para origem e 'dst' para destino\n",
    "# Troca nome \"FromNodeId\" por \"src\" e \"ToNodeId\" por \"dst\"\n",
    "edge = edge.withColumnRenamed(\"FromNodeId\", \"src\") \\\n",
    "           .withColumnRenamed(\"ToNodeId\", \"dst\").cache()\n",
    "\n",
    "edge.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                name|\n",
      "+---+--------------------+\n",
      "|  0|      Abbotsford, BC|\n",
      "|  1|        Aberdeen, SD|\n",
      "|  2|         Abilene, TX|\n",
      "|  3|    Akron/Canton, OH|\n",
      "|  4|         Alamosa, CO|\n",
      "|  5|          Albany, GA|\n",
      "|  6|          Albany, NY|\n",
      "|  7|     Albuquerque, NM|\n",
      "|  8|      Alexandria, LA|\n",
      "|  9|Allentown/Bethleh...|\n",
      "| 10|        Alliance, NE|\n",
      "| 11|          Alpena, MI|\n",
      "| 12|         Altoona, PA|\n",
      "| 13|        Amarillo, TX|\n",
      "| 14|       Anchorage, AK|\n",
      "| 15|        Appleton, WI|\n",
      "| 16|       Asheville, NC|\n",
      "| 17|           Aspen, CO|\n",
      "| 18|          Athens, GA|\n",
      "| 19|         Atlanta, GA|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:169: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+\n",
      "|src|dst|Weight|\n",
      "+---+---+------+\n",
      "| 27|  0|  -757|\n",
      "| 57|  0|   -84|\n",
      "| 70|  0| -1290|\n",
      "| 74|  0|  -465|\n",
      "| 86|  0|  -700|\n",
      "| 94|  0|  -526|\n",
      "|100|  0|  -448|\n",
      "|113|  0|   -90|\n",
      "|138|  0|  -256|\n",
      "|154|  0|  -270|\n",
      "|166|  0|  -515|\n",
      "|178|  0|  -400|\n",
      "|230|  0|  -486|\n",
      "|235|  0|  -170|\n",
      "|242|  0|  -469|\n",
      "|246|  0|  -325|\n",
      "|262|  0|  -200|\n",
      "|269|  0|  -525|\n",
      "|275|  0|  -585|\n",
      "|280|  0|  -405|\n",
      "+---+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a GraphFrame graph\n",
    "g = GraphFrame(vertice, edge)\n",
    "\n",
    "# Print vertices and edges\n",
    "g.vertices.show()\n",
    "g.edges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-degree of each vertex in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:148: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                name|inDegree|\n",
      "+--------------------+--------+\n",
      "|     Los Angeles, CA|     443|\n",
      "|   San Francisco, CA|     441|\n",
      "|Dallas/Fort Worth...|     432|\n",
      "|       Las Vegas, NV|     429|\n",
      "|         Chicago, IL|     429|\n",
      "|        New York, NY|     428|\n",
      "|          Denver, CO|     427|\n",
      "|      Washington, DC|     425|\n",
      "|         Phoenix, AZ|     423|\n",
      "|  Seattle/Tacoma, WA|     418|\n",
      "|Minneapolis/St Pa...|     411|\n",
      "|         Orlando, FL|     407|\n",
      "|         Toronto, ON|     404|\n",
      "|    Philadelphia, PA|     403|\n",
      "|       St. Louis, MO|     401|\n",
      "|         Houston, TX|     400|\n",
      "|  Ft. Lauderdale, FL|     400|\n",
      "|          Boston, MA|     399|\n",
      "|       San Diego, CA|     397|\n",
      "|         Detroit, MI|     393|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aeroportos com mais chegadas\n",
    "\n",
    "g.inDegrees.join(airport_name, on=['id'], how='inner').select(\"name\", \"inDegree\").orderBy(\"inDegree\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle Count for each vertice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                name|count|\n",
      "+--------------------+-----+\n",
      "|     Los Angeles, CA|36684|\n",
      "|   San Francisco, CA|36483|\n",
      "|Dallas/Fort Worth...|36283|\n",
      "|       Las Vegas, NV|36238|\n",
      "|         Chicago, IL|36078|\n",
      "|         Phoenix, AZ|35964|\n",
      "|          Denver, CO|35960|\n",
      "|  Seattle/Tacoma, WA|35832|\n",
      "|      Washington, DC|35658|\n",
      "|Minneapolis/St Pa...|35473|\n",
      "|    Philadelphia, PA|35274|\n",
      "|        New York, NY|35188|\n",
      "|         Atlanta, GA|34886|\n",
      "|         Detroit, MI|34867|\n",
      "|         Houston, TX|34740|\n",
      "|        Portland, OR|34454|\n",
      "|       Charlotte, NC|34352|\n",
      "|  Ft. Lauderdale, FL|34268|\n",
      "|         Memphis, TN|34193|\n",
      "|          Boston, MA|34072|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of triagles in each vertice\n",
    "\n",
    "g.triangleCount().select(\"name\", \"count\").orderBy(\"count\",ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breadth-first search (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/21 11:14:02 WARN BlockManager: Block rdd_175_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|distances|\n",
      "+---+---------+\n",
      "|315| {0 -> 2}|\n",
      "|386| {0 -> 2}|\n",
      "|454| {0 -> 2}|\n",
      "|365| {0 -> 2}|\n",
      "|451| {0 -> 1}|\n",
      "|384| {0 -> 2}|\n",
      "|324| {0 -> 1}|\n",
      "|180| {0 -> 2}|\n",
      "|320| {0 -> 2}|\n",
      "|373| {0 -> 2}|\n",
      "|369| {0 -> 2}|\n",
      "|408| {0 -> 2}|\n",
      "|307| {0 -> 2}|\n",
      "|428| {0 -> 2}|\n",
      "| 11| {0 -> 2}|\n",
      "| 14| {0 -> 2}|\n",
      "|346| {0 -> 2}|\n",
      "| 24| {0 -> 2}|\n",
      "|302| {0 -> 2}|\n",
      "|146| {0 -> 2}|\n",
      "+---+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run BFS algorithm, and show results. Shortest distance to landmarks 0 and 280\n",
    "\n",
    "g.shortestPaths(landmarks=[\"0\"]).select(\"id\", \"distances\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                name|          pagerank|\n",
      "+--------------------+------------------+\n",
      "|     Los Angeles, CA|2.8123266124650077|\n",
      "|   San Francisco, CA| 2.800641941117831|\n",
      "|Dallas/Fort Worth...|2.7460240561317035|\n",
      "|         Chicago, IL|2.7284968614992158|\n",
      "|       Las Vegas, NV|2.7185207578102104|\n",
      "|        New York, NY| 2.717765762525016|\n",
      "|          Denver, CO| 2.709805369163426|\n",
      "|      Washington, DC| 2.697910235841779|\n",
      "|         Phoenix, AZ| 2.685892902162765|\n",
      "|  Seattle/Tacoma, WA|2.6569722720794258|\n",
      "|Minneapolis/St Pa...|2.6131209497398773|\n",
      "|         Orlando, FL|2.5758475670025924|\n",
      "|         Toronto, ON|2.5538427064279436|\n",
      "|    Philadelphia, PA| 2.552884494022143|\n",
      "|         Houston, TX| 2.542357203429309|\n",
      "|       St. Louis, MO|2.5378217637515204|\n",
      "|  Ft. Lauderdale, FL| 2.534686007850658|\n",
      "|          Boston, MA| 2.532035189003591|\n",
      "|       San Diego, CA| 2.512212403087814|\n",
      "|         Detroit, MI|2.4958716324639934|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run PageRank algorithm, and show results.\n",
    "pagerank = g.pageRank(resetProbability=0.01, maxIter=20)\n",
    "#pagerank = g.pageRank(resetProbability=0.01, tol=0.001)\n",
    "\n",
    "pagerank.vertices.select(\"name\", \"pagerank\").orderBy(\"pagerank\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Execution time: 19.322293043136597 seconds ---\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "print(\"--- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
